{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. RDD 고급 개념\n",
    "\n",
    "- 집계와 키-값 형태의 RDD\n",
    "- 사용자 정의 파티셔닝\n",
    "- RDD 조인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5dc172a2377c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 12장에서 사용된 데이터 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmyCollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Spark The Definitive Guide: Big Data Processing Made Simple'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# 12장에서 사용된 데이터 불러오기 \n",
    "myCollection = 'Spark The Definitive Guide: Big Data Processing Made Simple'.split(' ')\n",
    "words = spark.sparkContext.parallelize(myCollection, 2)\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 키-값 형태의 기초(RDD)\n",
    "- ByKey가 있다면 pariRDD 타입만 사용할 수 있음\n",
    "- RDD에 맵 연산을 수행해 키-값 구조로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e72e2ba5457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words.map(lambda word: (word.lower(), 1)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.1 keyBy\n",
    "- 현재 값으로부터 키를 생성하는 KeyBy 함수를 사용하면 동일한 결과 반환\n",
    "- 스파크는 원본 단어를 생성된 RDD의 값으로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-38d24deacee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeyword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "keyword = words.keyBy(lambda word: word.lower()[0])\n",
    "keyword.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.2 값 매핑하기 \n",
    "- 튜플 형태의 데이터를 사용하면 스파크는 튜플의 첫 번째 요소를 키로, 두 번째 요소를 값으로 추정함\n",
    "- mapValues를 쓰면 값 수정 시 발생할 수 있는 오류를 미리 방지할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 'SPARK'),\n",
       " ('t', 'THE'),\n",
       " ('d', 'DEFINITIVE'),\n",
       " ('g', 'GUIDE:'),\n",
       " ('b', 'BIG'),\n",
       " ('d', 'DATA'),\n",
       " ('p', 'PROCESSING'),\n",
       " ('m', 'MADE'),\n",
       " ('s', 'SIMPLE')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.mapValues(lambda word: word.upper()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flatMap 함수를 사용해 반환되는 결과의 각 로우가 문자를 나타내도록 확장할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 'S'),\n",
       " ('s', 'P'),\n",
       " ('s', 'A'),\n",
       " ('s', 'R'),\n",
       " ('s', 'K'),\n",
       " ('t', 'T'),\n",
       " ('t', 'H'),\n",
       " ('t', 'E'),\n",
       " ('d', 'D'),\n",
       " ('d', 'E')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.flatMapValues(lambda word: word.upper()).collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.3 키와 값 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키\n",
      "['s', 't', 'd', 'g', 'b', 'd', 'p', 'm', 's']\n",
      "값\n",
      "['Spark', 'The', 'Definitive', 'Guide:', 'Big', 'Data', 'Processing', 'Made', 'Simple']\n"
     ]
    }
   ],
   "source": [
    "print('키')\n",
    "print(keyword.keys().collect())\n",
    "print('값')\n",
    "print(keyword.values().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.4 lookup\n",
    "- 특정 키에 대한 결과를 찾을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Simple']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.lookup('s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.5 sampleByKey\n",
    "- 근사치나 정확도를 이용해 키를 기반으로 RDD 샘플 생성\n",
    "- 부분 샘플링 할 수 있고, 비복원 추출도 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 'The'), ('t', 'The'), ('g', 'Guide:')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매번 추출 결과가 다르게 나온다.\n",
    "import random\n",
    "distinctChars = words.flatMap(lambda word: list(word.lower())).distinct().collect()\n",
    "sampleMap = dict(map(lambda c: (c,random.random()), distinctChars))\n",
    "words.map(lambda word: (word.lower()[0], word)).sampleByKey(True, sampleMap, 6).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sampleByKeyExact 매서드는 99.99% 신뢰도를 가진 모든 키값에 대해 RDD를 추가로 처리함\n",
    "- 비복원 추출을 사용한다면 샘플 크기를 보장하기 위해 RDD를 한번 더 통과해야 하고, 복원 추출을 사용한다면 RDD를 두번 더 통과해야함.\n",
    "- pyspark에는 구현 안되어 있는듯..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 집계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = words.flatMap(lambda word: word.lower())\n",
    "KVcharacters = chars.map(lambda letter: (letter, 1))\n",
    "\n",
    "def maxFunc(left, right):\n",
    "    return max(left, right)\n",
    "\n",
    "def addFunc(left, right):\n",
    "    return left + right\n",
    "\n",
    "nums = sc.parallelize(range(1,31), 5)\n",
    "nums.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2.1 countByKey\n",
    "- 각 키의 아이템 수를 구하고 로컬 맵으로 결과를 수집함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'s': 4,\n",
       "             'p': 3,\n",
       "             'a': 4,\n",
       "             'r': 2,\n",
       "             'k': 1,\n",
       "             't': 3,\n",
       "             'h': 1,\n",
       "             'e': 7,\n",
       "             'd': 4,\n",
       "             'f': 1,\n",
       "             'i': 7,\n",
       "             'n': 2,\n",
       "             'v': 1,\n",
       "             'g': 3,\n",
       "             'u': 1,\n",
       "             ':': 1,\n",
       "             'b': 1,\n",
       "             'o': 1,\n",
       "             'c': 1,\n",
       "             'm': 2,\n",
       "             'l': 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2.2 집계 연산 구현 방식 이해하기\n",
    "\n",
    "- groupByKey\n",
    " - 각 키의 총 레코드를 수를 구하는 경우 groupByKey의 결과로 만들어진 그룹에 map 연산을 수행하는 방식을 추천\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 4),\n",
       " ('p', 3),\n",
       " ('r', 2),\n",
       " ('h', 1),\n",
       " ('d', 4),\n",
       " ('i', 7),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 4),\n",
       " ('k', 1),\n",
       " ('t', 3),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "KVcharacters.groupByKey().map(lambda row: (row[0], reduce(addFunc, row[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 방식에서 가장 큰 문제는 모든 익스큐터에서 함수를 적용하기 전에 해당 키와 관련된 모든 값을 메모리로 읽어 들여야하는것! \n",
    "- 심각하게 치우쳐진 키가 있다면 일부 파티션에만 엄청난 값을 가질 수 있기 때문에 OutOfMemoryError 발생\n",
    "- 대규모 분산 환경에서는 심각한 에러 발생\n",
    "- 그러므로 이 방식은 각 키에 대한 값의 크기가 일정하고 익스큐터에 할당된 메모리에서 처리 가능할 정도일 경우에만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reduceByKey\n",
    " - 각 파티션에서 리듀스 작업을 수행하기 때문에 훨씬 안정적이며 모든 값을 메모리에 유지하지 않아도 됨\n",
    " - 리듀스 과정을 제외한 모든 작업은 개별 워커에서 처리하기 때문에 연산 중에 셔플이 발생하지 않음\n",
    " - 키별 그룹 RDD를 반환함. 개별 요소들은 따로 정렬되지 않음, 따라서 순서가 중요할 때는 사용하지 않는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 4),\n",
       " ('p', 3),\n",
       " ('r', 2),\n",
       " ('h', 1),\n",
       " ('d', 4),\n",
       " ('i', 7),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 4),\n",
       " ('k', 1),\n",
       " ('t', 3),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.reduceByKey(addFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2.3 기타 집계 메서드\n",
    "- 고급 집계 함수를 사용해 클러스터 노드에서 수행하는 집계를 아주 구체적이고 매우 세밀하게 제어할 수 있음\n",
    "\n",
    "- aggregate\n",
    " - null 값이나 집계의 시작값이 필요하고 두 가지 파라미터를 사용함\n",
    " - 드라이버에서 최종 집계를 수행하기 때문에 성능에 약간의 영향을 끼침\n",
    " - 익스큐터가 너무 크면 OutOfMemoryError 발생 \n",
    " - treeAggregate는 동일한 작업이지만 처리 과정이 다름\n",
    "   - 드라이버에서 최종 집계를 수행하기 전에 익스큐터끼리 트리를 형성해 집계 처리의 일부 하위 과정을 '푸시 다운' 방식으로 먼저 수행함\n",
    "   - 집계 처리를 여러 단계로 구성하면 드라이버의 메모리를 모두 소비하는 현상을 막아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 함수는 파티션 내에서 수행되고 두 번째 함수는 모든 파티션에 걸쳐 수행됨 \n",
    "nums.aggregate(0, maxFunc, addFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 3\n",
    "nums.treeAggregate(0, maxFunc, addFunc, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aggregateByKey\n",
    " - 파티션 대신 키를 기준으로 연산을 수행함\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 3),\n",
       " ('p', 2),\n",
       " ('r', 1),\n",
       " ('h', 1),\n",
       " ('d', 2),\n",
       " ('i', 4),\n",
       " ('g', 2),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 3),\n",
       " ('k', 1),\n",
       " ('t', 2),\n",
       " ('e', 4),\n",
       " ('f', 1),\n",
       " ('n', 1),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.aggregateByKey(0,addFunc,maxFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- combineByKEy\n",
    " - 집계함수 대신 컴바이너 사용\n",
    " - 키를 기준으로 연산을 수행하며 파라미터로 사용된 함수에 따라 값을 병행함\n",
    " - 여러 컴바이너의 결괏값을 병합해 결과를 반환함\n",
    " - 사용자 정의 파티셔너를 사용해 출력 파티션 수를 지정할 수 있음\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', [1, 1, 1, 1]),\n",
       " ('d', [1, 1, 1, 1]),\n",
       " ('l', [1]),\n",
       " ('v', [1]),\n",
       " (':', [1]),\n",
       " ('p', [1, 1, 1]),\n",
       " ('r', [1, 1]),\n",
       " ('c', [1]),\n",
       " ('k', [1]),\n",
       " ('t', [1, 1, 1]),\n",
       " ('n', [1, 1]),\n",
       " ('u', [1]),\n",
       " ('o', [1]),\n",
       " ('h', [1]),\n",
       " ('i', [1, 1, 1, 1, 1, 1, 1]),\n",
       " ('g', [1, 1, 1]),\n",
       " ('b', [1]),\n",
       " ('a', [1, 1, 1, 1]),\n",
       " ('e', [1, 1, 1, 1, 1, 1, 1]),\n",
       " ('f', [1]),\n",
       " ('m', [1, 1])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def valToCombiner(value):\n",
    "    return [value]\n",
    "\n",
    "def mergeValuesFunc(vals, valToAppend):\n",
    "    vals.append(valToAppend)\n",
    "    return vals\n",
    "\n",
    "def mergeCombinerFunc(vals1, vals2):\n",
    "    return vals1 + vals2\n",
    "outputPartitions = 6\n",
    "\n",
    "KVcharacters.combineByKey(valToCombiner, mergeValuesFunc, mergeCombinerFunc, outputPartitions).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- foldByKey\n",
    " - 결합 함수와 항등원인 '제로값'을 이용해 각 키의 값을 병합함\n",
    " - 제로값은 결과에 여러번 사용할 수 있으나 결과를 변경할 수는 없음(덧셈에서는 0, 뺄셈에서는 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 4),\n",
       " ('p', 3),\n",
       " ('r', 2),\n",
       " ('h', 1),\n",
       " ('d', 4),\n",
       " ('i', 7),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 4),\n",
       " ('k', 1),\n",
       " ('t', 3),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.foldByKey(0, addFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 cogroup\n",
    "- 스칼라는 최대 3개, 파이썬은 최대 2개의 키-값 형태의 RDD를 그룹화할 수 있으며 각 키를 기준으로 결합함. \n",
    "- RDD에 대한 그룹 기반의 조인을 수행함\n",
    "- 출력 파티션 수나 클러스터에 데이터 분산 방식을 정확하게 제어하기 위해 사용자 정의 파티션 함수를 파라미터로 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f5c5da0f748>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f5c5da3e0b8>)),\n",
       " ('p',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f5c5da090f0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f5c5da3e128>)),\n",
       " ('r',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f5c5da3e160>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f5c5da3e198>)),\n",
       " ('i',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f5c5da3e0f0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f5c5da3e208>)),\n",
       " ('g',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f5c5da3e240>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f5c5da3e278>))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "distinctChars = words.flatMap(lambda word: word.lower()).distinct()\n",
    "charRDD = distinctChars.map(lambda c: (c, random.random()))\n",
    "charRDD2 = distinctChars.map(lambda c: (c, random.random()))\n",
    "\n",
    "charRDD.cogroup(charRDD2).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4 조인\n",
    "- 구조적 API와 비슷한 조인 방식을 가지고 있지만, RDD는 사용자가 많은 부분에 관여해야함\n",
    "- 출력 파티션 수나 사용자 정의 파티션 함수를 파라미터로 사용함 \n",
    "\n",
    "#### 13.4.1 내부 조인\n",
    "- 조인 방식\n",
    " 1. fullOuterJoin\n",
    " 2. leftOuterJoin\n",
    " 3. rightOuterJoin\n",
    " 4. cartesian(조인 키를 사용하지 않기 때문에 엄청 큰 출력 결과를 만들 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "keyedChars = distinctChars.map(lambda c: (c, random.random()))\n",
    "outputPartitions = 10\n",
    "\n",
    "print(KVcharacters.join(keyedChars).count())\n",
    "print(KVcharacters.join(keyedChars, outputPartitions).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.4.2 zip\n",
    "- 두개의 RDD를 결합하는 방식\n",
    "- 동일한 길이의 두 개의 RDD를 지퍼를 잠그듯 연결할 수 있고, pairRDD 생성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 0),\n",
       " ('The', 1),\n",
       " ('Definitive', 2),\n",
       " ('Guide:', 3),\n",
       " ('Big', 4),\n",
       " ('Data', 5),\n",
       " ('Processing', 6),\n",
       " ('Made', 7),\n",
       " ('Simple', 8)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRange = sc.parallelize(range(9), 2)\n",
    "words.zip(numRange).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5 파티션 제어하기\n",
    "- RDD를 사용하면 데이터가 클러스터 전체에 물리적으로 정확히 분산되는 방식을 정의할 수 있음\n",
    "- 구조적 API와 가장 큰 차이점은 파티션 함수를 파라미터로 사용할 수 있다는 것\n",
    "\n",
    "#### 13.5.1 coalesce\n",
    "- 파티션을 재분배할 때 발생하는 데이터 셔플을 방지하기 위해 동일한 워커에 존재하는 파티션을 합치는 매서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.coalesce(1).getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5.2 repartition\n",
    "- 파티션 수를 늘리거나 줄일 수 있지만, 처리 시 노드 간의 셔플이 발생할 수 있음\n",
    "- 파티션 수를 늘리면 맵 타입이나 필터 타입의 연산을 수행할 때 병렬 처리 수준을 높일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark',\n",
       " 'The',\n",
       " 'Definitive',\n",
       " 'Guide:',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Processing',\n",
       " 'Made',\n",
       " 'Simple']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.repartition(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.5.3 repartitionAndSortWithinPartitions\n",
    "- 파티션을 재분배할 수 있고, 재분배된 결과 파티션의 정렬 방식을 지정할 수 있음\n",
    "- 파티셔닝과 키 비교 모두 사용자가 지정할 수 있음\n",
    "\n",
    "#### 13.5.4 사용자 정의 파티셔닝\n",
    "- 저수준 API의 세부적인 구현 방식\n",
    "- 페이지랭크는 사용자의 정의 파티셔닝을 이용해 클러스터의 데이터 배치 구조를 제어하고 셔플을 회피함.\n",
    "- 데이터 치우침 같은 문제를 피하고자 클러스터 전체에 걸쳐 데이터를 균등하게 분배\n",
    "- 사용자 정의 파티셔너를 사용하려면 구조적 API로 RDD를 얻고 사용자 정의 파티셔너를 적용한 다음 다시 DataFrame이나 Dataset으로 변환해야함.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header','true').option('inferSchema', 'true').csv('file:///home/ubuntu/Spark-The-Definitive-Guide/data/retail-data/all')\n",
    "rdd = df.coalesce(10).rdd\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HashPartitioner는 이산형 데이터\n",
    "- RangePArtitioner는 연속형 데이터 \n",
    "- 매우 큰 데이터나 심각하게 치우친 키를 다뤄야 하면 고급 파티셔닝 기능을 사용해야함. \n",
    "- 병렬성을 개선하고 실행 과정에서 OutOfMemoryError를 방지할 수 있도록 키를 최대한 분할해야함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4301, 4304]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partitionFunc(key):\n",
    "  import random\n",
    "  if key == 17850 or key == 12583:\n",
    "    return 0\n",
    "  else:\n",
    "    return random.randint(1,2)\n",
    "\n",
    "keyedRDD = rdd.keyBy(lambda row: row[6])\n",
    "keyedRDD\\\n",
    "  .partitionBy(3, partitionFunc)\\\n",
    "  .map(lambda x: x[0])\\\n",
    "  .glom()\\\n",
    "  .map(lambda x: len(set(x)))\\\n",
    "  .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.6 사용자 정의 직렬화\n",
    "- Kryo를 사용하면 더 빠르게 객체를 직렬화 할 수 있음\n",
    "- 자바 직렬화보다 약 10배 이상 성능이 좋고 간결함\n",
    "- spark.serralizer 설정으로 워커 노드 간 데이터 셔플링과 RDD를 직렬화해 디스크에 저장하는 용도로 사용할 시리얼라이저를 지정할 수 있음.\n",
    "- 네트워크에 민감한 애플리케이션에서 사용할 것을 권장\n",
    "- 스파크 2 버전부터는 단순 데이터 타입, 배열, 문자열 데이터 타입의 RDD를 셔플링하면 내부적으로 Kyro 시리얼라이저를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
