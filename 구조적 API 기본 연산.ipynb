{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 구조적 API 기본 연산\n",
    "- DataFrame은 row 타입의 레코드와 각 레코드를 수행할 연산 표현식을 나타내는 여러 컬럼으로 구성\n",
    "- 스키마는 각 컬럼명과 데이터 타입 정의\n",
    "- DataFrame의 파티셔닝은 DataFrame이나 Dataset이 클러스터에서 물리적으로 배치되는 형태를 정의\n",
    "- 파티셔닝 스키마는 파티션을 배치하는 방법을 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 생성 방식\n",
    "df = spark.read.format('json').load('file:///home/ubuntu/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스키마 확인 과정\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 스키마\n",
    "- 스키마는 DataFrame의 컬럼명과 데이터 타입을 정의함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format('json').load('file:///home/ubuntu/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json').schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스키마는 여러 개의 StructField 타입 필드로 구성된 StructType 객체\n",
    "- 스키마는 복합 데이터 타입인 StructType을 가질 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "    StructField('DEST_COUNTRY_NAME', StringType(), True),\n",
    "    StructField('ORIGIN_COUNTRY_NAME', StringType(), True),\n",
    "    StructField('count', LongType(), False, metadata = {'hello': 'world'})\n",
    "])\n",
    "df = spark.read.format('json').schema(myManualSchema).load('file:///home/ubuntu/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 컬럼과 표현식\n",
    "- Pandas와 유사한 표현식을 가짐\n",
    "\n",
    "#### 5.2.1 컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<b'someColumnName'>\n",
      "Column<b'someColumnName'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column\n",
    "\n",
    "print(col('someColumnName'))\n",
    "print(column('someColumnName'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컬럼은 컬럼명을 카탈로그에 저장된 정보와 비교하기 전꺼지 미확인 상태로 남음. -> 분석기가 동작하는 단계에서 컬럼과 테이블을 분석함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 표현식\n",
    "- DataFrame 레코드의 여러 값에 대한 트랜스포메이션 집합을 의미함\n",
    "- expr('somecolumn') = col('somecolumn')\n",
    "- expr('somecolumn - 5') = col('somecolumn') - 5 = expr('somecolumn) - 5\n",
    "- 위의 예제가 같은 이유는 스파크가 연산 순서를 지정하는 논리적 트리로 컴파일하기 때문임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'((((someCol + 5) * 200) - 6) < otherCol)'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "expr(\"(((someCol + 5) * 200) - 6) < otherCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL의 Select 구문에 이전 표현식을 사용해도 잘 동작하고 동일한 결과 반환\n",
    "- 실행 시점에 동일한 논리 트리로 컴파일되기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 컬럼에 접근하기\n",
    "spark.read.format('json').load('file:///home/ubuntu/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 레코드와 로우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 로우 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "myRow = Row('Hello', None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 로우 데이터에 접근하는 방식\n",
    "print(myRow[0])\n",
    "print(myRow[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 DataFrame의 트랜스포메이션\n",
    "- 로우나 컬럼 추가\n",
    "- 로우나 컬럼 제거\n",
    "- 로우를 컬럼으로 변환하거나, 그 반대로 변환\n",
    "- 컬럼값을 기준으로 로우 순서 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 생성 방식\n",
    "# 임시 뷰 등록 방식\n",
    "df = spark.read.format('json').load('file:///home/ubuntu/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json')\n",
    "df.createOrReplaceTempView('dfTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| Some| col|names|\n",
      "+-----+----+-----+\n",
      "|Hello|null|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# row 객체를 가진 seq 타입을 직접 변환해 DataFrame 생성할 수 있음\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "mySchema = StructType([\n",
    "    StructField('Some', StringType(), True),\n",
    "    StructField('col', StringType(), True),\n",
    "    StructField('names', LongType(), False)\n",
    "])\n",
    "\n",
    "myRow = Row('Hello', None, 1)\n",
    "myDf = spark.createDataFrame([myRow], mySchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select와 selectExpr을 사용하면 SQL을 실행한 것처럼 DataFrame에 적용가능\n",
    "df.select('DEST_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러 컬럼 선택하는 방법\n",
    "df.select('DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러 방식으로 섞어서 사용 가능\n",
    "df.select(expr('DEST_COUNTRY_NAME'), col('DEST_COUNTRY_NAME'), column('DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컬럼 객체와 문자열을 함께 쓰면 에러 생김.\n",
    "- expr은 가장 유연한 참조 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  destination|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr('DEST_COUNTRY_NAME as destination')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼명을 바꾸는 방식은 두가지로 할 수 있음\n",
    "df.select(expr('DEST_COUNTRY_NAME as destination').alias('DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|newCOlumnName|DEST_COUNTRY_NAME|\n",
      "+-------------+-----------------+\n",
      "|United States|    United States|\n",
      "|United States|    United States|\n",
      "+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selectExpr로 한번에 할 수 있음\n",
    "df.selectExpr('DEST_COUNTRY_NAME as newCOlumnName', 'DEST_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- selectExpr을 통해 복잡한 표현식을 간단하게 만들 수 있음\n",
    "- 비집계형 SQL 구문도 지정할 수 있음\n",
    "- 단 컬럼을 식별해야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"*\", '(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry' ).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+\n",
      "| avg(count)|count(DISTINCT DEST_COUNTRY_NAME)|\n",
      "+-----------+---------------------------------+\n",
      "|1770.765625|                              132|\n",
      "+-----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 집계함수 지정\n",
    "df.selectExpr('avg(count)', 'count(distinct(DEST_COUNTRY_NAME))').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3 스파크 데이터 타입으로 변환\n",
    "- 새로운 컬럼이 아닌 명시적인 값을 스파크에 전달해야될 경우, 리터럴을 사용함\n",
    "- 리터럴은 프로그래밍 언어의 리터럴값을 스파크가 이해할 수 있는 값으로 변환\n",
    "- SQL에서 리터럴은 상숫값을 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|one|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(expr(\"*\"), lit(1).alias('one')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.4 컬럼 추가\n",
    "- withColumn 매서드를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('numberOne', lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-----------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withCountry|\n",
      "+-----------------+-------------------+-----+-----------+\n",
      "|    United States|            Romania|   15|      false|\n",
      "|    United States|            Croatia|    1|      false|\n",
      "+-----------------+-------------------+-----+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 출발지와 도착지가 같은지 여부를 불리언 타입으로 표현하는 예제\n",
    "df.withColumn('withCountry', expr('ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count', 'Destination']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# withColumn으로 컬럼명 바꾸는 예제\n",
    "df.withColumn('Destination', expr('DEST_COUNTRY_NAME')).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# withColumnRenamed로도 변경 가능\n",
    "df.withColumnRenamed('DEST_COUNTRY_NAME', 'DEST').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+\n",
      "|this long column-name|new col|\n",
      "+---------------------+-------+\n",
      "|              Romania|Romania|\n",
      "|              Croatia|Croatia|\n",
      "+---------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n",
      "+---------------------+-------+\n",
      "|this long column-name|new col|\n",
      "+---------------------+-------+\n",
      "|              Romania|Romania|\n",
      "|              Croatia|Croatia|\n",
      "+---------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 예약 문자와 키워드는 컬럼명에 사용할 수 없음(공백이나 하이픈(-))\n",
    "# 예약 문자를 컬럼에 사용하려면 '을 통해 이스케이핑 해야함\n",
    "# 만들때는 문제 없지만, 불러올때는 활용해야함\n",
    "# 표현식 대신에 문자열을 사용해 명시적으로 컬럼을 참조하면 리터럴로 해석되기 때문에 예약 문자가 포함된 컬럼을 참조할 수 있음\n",
    "\n",
    "dfwithLongColName = df.withColumn('This long column-name',\n",
    "                                 expr('origin_country_name'))\n",
    "print(dfwithLongColName.selectExpr('`this long column-name`',\n",
    "                            '`this long column-name` as `new col`').show(2))\n",
    "print(dfwithLongColName.selectExpr('`this long column-name`',\n",
    "                            '`this long column-name` as `new col`').show(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스파크는 기본적으로 대소문자 구분하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 제거\n",
    "df.drop('ORIGIN_COUNTRY_NAME').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[count: bigint, This long column-name: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한번에 제거\n",
    "dfwithLongColName.drop('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint, count2: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 타입 변경\n",
    "df.withColumn('count2', col('count').cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# filter와 where는 비슷한 역할을 함.\n",
    "print(df.filter(col('count') < 2).show(2))\n",
    "print(df.where('count < 2').show(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러개 필터링 해야되는 경우 and로 차례대로 연결하고, 판단은 스파크에 맡긴다. \n",
    "df.where(col('count') < 2).where(col('ORIGIN_COUNTRY_NAME')!= 'Croatia').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고유한 로우는 distinct를 사용함\n",
    "# 하나 이상의 로우를 사용해야함\n",
    "df.select('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('ORIGIN_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 무작위 샘플 만들기\n",
    "seed = 5\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의로 분할하기\n",
    "# seed가 꼭 필요함\n",
    "dataFrames = df.randomSplit([0.25, 0.75], seed)\n",
    "dataFrames[0].count() > dataFrames[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame은 불변성을 가지기 때문에 레코드를 추가하려면 원본과 새로운 DataFrame을 통합해야함. \n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "schema = df.schema\n",
    "newRows = [\n",
    "    Row(\"New Country\", \"Other Country\", 5),\n",
    "    Row(\"New New Country\", \"Other Country\", 1)\n",
    "]\n",
    "\n",
    "parallelizedRows = spark.sparkContext.parallelize(newRows)\n",
    "newDF = spark.createDataFrame(parallelizedRows, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|      New Country|      Other Country|    5|\n",
      "|  New New Country|      Other Country|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "|  New New Country|      Other Country|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.union(newDF).where('count = 1').where(col('ORIGIN_COUNTRY_NAME') != 'United States').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "|           Canada|      United States|  8399|\n",
      "|    United States|             Mexico|  7187|\n",
      "|           Mexico|      United States|  7140|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 로우 정렬하기\n",
    "print(df.sort('count').show(5))\n",
    "print(df.orderBy('count', 'DEST_COUNTRY_NAME').show(5))\n",
    "print(df.orderBy(col('count').desc(), col('DEST_COUNTRY_NAME').asc()).show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파티션별 정렬 수행 -> 성능 최적화\n",
    "spark.read.format('json').load('file:///home/ubuntu/Spark-The-Definitive-Guide/data/flight-data/json/*-summary.json').sortWithinPartitions('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 로우 수 제한\n",
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]\n",
      "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]\n",
      "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "# 자주 필터링하는 컬럼 기준으로 데이터 분할\n",
    "print(df.rdd.getNumPartitions())\n",
    "print(df.repartition(5))\n",
    "print(df.repartition(col('DEST_COUNTRY_NAME')))\n",
    "print(df.repartition(5, col('DEST_COUNTRY_NAME')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터를 셔플하지 않고 파티션을 병합하는 경우\n",
    "print(df.repartition(5, col('DEST_COUNTRY_NAME')).coalesce(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Grenada', count=62),\n",
       " Row(DEST_COUNTRY_NAME='Costa Rica', ORIGIN_COUNTRY_NAME='United States', count=588),\n",
       " Row(DEST_COUNTRY_NAME='Senegal', ORIGIN_COUNTRY_NAME='United States', count=40),\n",
       " Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스파크는 드라이버에서 클러스터 상태 정보 유지\n",
    "collectDF = df.limit(10)\n",
    "collectDF.take(5)\n",
    "collectDF.show()\n",
    "collectDF.show(5)\n",
    "collectDF.show(5, False)\n",
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x7f0d7c84f0b8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반복 처리를 위한 메서드\n",
    "collectDF.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
